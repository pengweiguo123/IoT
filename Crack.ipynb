{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as albu\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from numba import jit\n",
    "\n",
    "DATA_DIR = 'D:\\Pengwei/segmentation_models/data'\n",
    "\n",
    "x_train_dir = os.path.join(DATA_DIR, 'train_image') \n",
    "y_train_dir = os.path.join(DATA_DIR, 'train_label')\n",
    "#x_train_dir = os.path.join(DATA_DIR, 'Normal concrete') \n",
    "#y_train_dir = os.path.join(DATA_DIR, 'Normal_label')\n",
    "\n",
    "#x_valid_dir = os.path.join(DATA_DIR, 'val_image')\n",
    "#y_valid_dir = os.path.join(DATA_DIR, 'val_label')\n",
    "\n",
    "#x_test_dir = os.path.join(DATA_DIR, 'Test')\n",
    "x_test_dir = os.path.join(DATA_DIR, 'test_image')\n",
    "#y_test_dir = os.path.join(DATA_DIR, 'Label')\n",
    "y_test_dir = os.path.join(DATA_DIR, 'test_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \n",
    "    CLASSES = ['crack']\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            images_dir, \n",
    "            masks_dir, \n",
    "            classes=None, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.ids = os.listdir(images_dir)\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
    "        \n",
    "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(self.masks_fps[i], 0)\n",
    "        \n",
    "        # extract certain classes from mask (e.g. cars)\n",
    "        masks = [(mask == v) for v in self.class_values]\n",
    "        mask = np.stack(masks, axis=-1).astype('float')\n",
    "        \n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "\n",
    "        albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n",
    "\n",
    "        albu.PadIfNeeded(min_height=320, min_width=320, always_apply=True, border_mode=0),\n",
    "        albu.RandomCrop(height=320, width=320, always_apply=True),\n",
    "\n",
    "        albu.IAAAdditiveGaussianNoise(p=0.2),\n",
    "        albu.IAAPerspective(p=0.5),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.CLAHE(p=1),\n",
    "                albu.RandomBrightness(p=1),\n",
    "                albu.RandomGamma(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.IAASharpen(p=1),\n",
    "                albu.Blur(blur_limit=3, p=1),\n",
    "                albu.MotionBlur(blur_limit=3, p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.RandomContrast(p=1),\n",
    "                albu.HueSaturationValue(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        albu.PadIfNeeded(384, 480)\n",
    "    ]\n",
    "    return albu.Compose(test_transform)\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "ENCODER = 'resnet50'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['crack']\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multicalss segmentation\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=None, \n",
    "    classes=len(CLASSES), \n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "\n",
    "train_dataset = Dataset(\n",
    "    x_train_dir, \n",
    "    y_train_dir, \n",
    "    #augmentation=get_training_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,)\n",
    "\n",
    "val_percent = 0.2\n",
    "n_val = int(len(train_dataset) * val_percent)\n",
    "n_train = len(train_dataset) - n_val\n",
    "train, val = random_split(train_dataset, [n_train, n_val])\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=4, \n",
    "                              shuffle=True, num_workers=0, pin_memory=True)\n",
    "    \n",
    "valid_loader = DataLoader(val, batch_size=4, \n",
    "                              shuffle=False, num_workers=0, pin_memory=True, drop_last=True)\n",
    "\n",
    "loss = smp.utils.losses.DiceLoss()\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "    smp.utils.metrics.Precision(threshold=0.5),\n",
    "    smp.utils.metrics.Recall(threshold=0.5),\n",
    "    smp.utils.metrics.Fscore(threshold=0.5),  \n",
    "]\n",
    "\n",
    "optimizer = torch.optim.RMSprop([ \n",
    "    dict(params=model.parameters(), lr=0.0001),\n",
    "])\n",
    "\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,)\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE,\n",
    "    verbose=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model for 40 epochs\n",
    "max_score = 0\n",
    "\n",
    "loader_train = []\n",
    "loader_test = []\n",
    "for i in range(0, 30):\n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    loader_train.append(train_logs)\n",
    "    print(train_logs)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "    loader_test.append(valid_logs)\n",
    "    print(valid_logs)\n",
    "    # do something (save model, change lr, etc.)\n",
    "    if max_score < valid_logs['iou_score']:\n",
    "        max_score = valid_logs['iou_score']\n",
    "        torch.save(model, 'D:\\Pengwei/segmentation_models/best_model.pth')\n",
    "        print('Model saved!')\n",
    "        \n",
    "    if i == 25:\n",
    "        optimizer.param_groups[0]['lr'] = 1e-5\n",
    "        print('Decrease decoder learning rate to 1e-5!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the test dataset\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as albu\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from numba import jit\n",
    "ENCODER = 'resnet50'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['crack']\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multicalss segmentation\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "model = smp.Linknet(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=None, \n",
    "    classes=len(CLASSES), \n",
    "    activation=ACTIVATION,)\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "best_model = torch.load('D:\\segmentation_models/best_model.pth')\n",
    "test_dataset = Dataset(x_test_dir, preprocessing=get_preprocessing(preprocessing_fn))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for images in test_dataset:\n",
    "        img = images.reshape(images.shape[0], images.shape[1], images.shape[2])\n",
    "        x_tensor = torch.from_numpy(img).to(DEVICE).unsqueeze(0)\n",
    "        masks = best_model.predict(x_tensor)\n",
    "        #pred = np.array(masks.data.cpu()[0])[0]\n",
    "        pr_mask = (masks.squeeze().cpu().numpy().round())\n",
    "        pr_mask[pr_mask >= 0.5] = 255\n",
    "        img = cv2.cvtColor(pr_mask, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imwrite('D:/segmentation_models/data/%d.jpg'%i, img)\n",
    "        i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test single image\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "tfms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "PATH = 'D:\\pengwei/Smart robotic car/'\n",
    "path_save = 'D:\\pengwei/'\n",
    "img_path = \"D:\\Pengwei/segmentation_models/data/test_image/ECC.jpg\"\n",
    "seg_model = torch.load('D:\\Pengwei/segmentation_models/best_model.pth')\n",
    "#detect_model = torch.hub.load('ultralytics/yolov5', 'custom', path= PATH + 'best.pt')\n",
    "color_image = Image.open('D:\\Pengwei/segmentation_models/data/test_image/ECC.jpg')\n",
    "#color_image = Image.open('D:\\Pengwei/ruihua.jpg')\n",
    "#detected_crack = detect_model(color_image)\n",
    "\n",
    "img_tensor = tfms(color_image).to('cuda').unsqueeze(0)\n",
    "output = seg_model.predict(img_tensor)\n",
    "output = (output.squeeze().cpu().numpy().round())\n",
    "pred_mask = np.asarray(output, dtype=np.uint8)*255\n",
    "cv2.imwrite(path_save + 'segmented.png', pred_mask)\n",
    "#cv2.imwrite(path_save + 'detected.png', detected_crack.render()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average crack width is: 115.87595822166075\n",
      "25.582770586013794\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "import time\n",
    "import pandas as pd\n",
    "start = time.time()\n",
    "\n",
    "def crack_quantification(img,h_1,Actual_height):\n",
    "    COLORS = [[128,0,0],[255,0,0],[255,144,30],[255,255,0],[0,255,0],[0,255,127],[0,255,255],[18,153,255],\n",
    "              [0,97,255],[147,20,255],[0,0,255],[240,32,160]]\n",
    "    img = 255 - img\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    h,w = img.shape\n",
    "    img_new =np.zeros([h,w], np.uint8)\n",
    "    img_new_4 = np.zeros([h,w,3], np.uint8)\n",
    "    img_new_4.fill(255)\n",
    "    k = 0\n",
    "    crack_width_list = []\n",
    "    for i in range(len(contours)):\n",
    "        area = cv2.contourArea(contours[i])\n",
    "        Crack_width_list = []\n",
    "        if area > 300:\n",
    "            k+=1\n",
    "            img1 = cv2.drawContours(img_new,contours,i,255,thickness=-1)   \n",
    "            n = 0\n",
    "            x = int(h/h_1) \n",
    "            s = 0\n",
    "            g = h_1 \n",
    "            for j in range(x):\n",
    "                cropped = img1[s:g,0:w]\n",
    "                h1,w1 = cropped.shape\n",
    "                contours1, hierarchy1 = cv2.findContours(cropped,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "                for a in range(len(contours1)):\n",
    "                    img_new_1 = np.zeros([h1,w1], np.uint8)\n",
    "                    img2 = cv2.drawContours(img_new_1,contours1,a,255,thickness=-1)\n",
    "                    #cv2.imwrite(\"E:\\paper/Fast_detection/quantification/ooo/%d_\"%n +\"%d.png\"%a,img2)\n",
    "                    img_new_2 = np.zeros([h1,w1], np.uint8)\n",
    "                    if (img2 == img_new_2).all():\n",
    "                        actual_crack_width = 0\n",
    "                    else:\n",
    "                        threshold_level = 50\n",
    "                        coords = np.column_stack(np.where(img2 > threshold_level))\n",
    "                        #print(coords)\n",
    "                        coord_first = []\n",
    "                        coord_last = []\n",
    "                        for i in range(len(coords)):\n",
    "                            if coords[i][0] == coords[0][0]:\n",
    "                                coord_first.append(coords[i])\n",
    "                            if coords[i][0]==coords[-1][0]:\n",
    "                                coord_last.append(coords[i])\n",
    "                                \n",
    "                        y1 = coord_first[0][0]\n",
    "                        x1 = coord_first[0][1]\n",
    "                        y2 = coord_first[-1][0]\n",
    "                        x2 = coord_first[-1][1]\n",
    "                        y3 = coord_last[0][0]\n",
    "                        x3 = coord_last[0][1]\n",
    "                        y4 = coord_last[-1][0]\n",
    "                        x4 = coord_last[-1][1]\n",
    "                        \n",
    "                        if abs(x2-x4)==0:\n",
    "                            width_pixel = abs(x1-x2)\n",
    "                        else:\n",
    "                            D = abs(x2-x4)\n",
    "                            H = abs(y4-y2)\n",
    "                            L = math.sqrt((D**2)+(H**2))\n",
    "                            sina = D/L\n",
    "                            angle = math.asin(sina)\n",
    "                            angle_degree = math.degrees(angle)\n",
    "                            if angle_degree <= 45:\n",
    "                                cosa = math.cos(angle)\n",
    "                                W = abs(x1-x2)\n",
    "                                width_pixel = W*cosa \n",
    "                            if angle_degree > 45:\n",
    "                                D1 = abs(x2-x4)\n",
    "                                H1 = abs(y4-y2)\n",
    "                                L1 = math.sqrt((D1**2)+(H1**2))\n",
    "                                sina1 = D1/L1\n",
    "                                angle1 = math.asin(sina1)\n",
    "                                cosa1 = math.cos(angle1)\n",
    "                                W1 = abs(x1-x2)\n",
    "                                width_pixel = W1*cosa1\n",
    "                       \n",
    "                        actual_crack_width = abs(width_pixel)/(h/Actual_height)\n",
    "                        #actual_crack_width = Decimal(actual_crack_width).quantize(Decimal(\"0.00\"))    \n",
    "                        Crack_width_list.append(actual_crack_width)\n",
    "                        #print(\"the crack width for %d is:\"%k, Crack_width_list)\n",
    "                        for i in range(len(coords)):\n",
    "                            x = coords[i][0]\n",
    "                            y = coords[i][1]                      \n",
    "                            if float(actual_crack_width)!=0:\n",
    "                                if float(actual_crack_width)>0 and float(actual_crack_width)<=25:\n",
    "                                    img_new_4[s:g,0:w,:][x,y]= COLORS[0]\n",
    "                                if float(actual_crack_width)>25 and float(actual_crack_width)<=50:\n",
    "                                    img_new_4[s:g,0:w,:][x,y]= COLORS[1]\n",
    "                                if float(actual_crack_width)>50 and float(actual_crack_width)<=75:\n",
    "                                    img_new_4[s:g,0:w,:][x,y]= COLORS[2]\n",
    "                                if float(actual_crack_width)>75 and float(actual_crack_width)<=100:\n",
    "                                    img_new_4[s:g,0:w,:][x,y]= COLORS[3]\n",
    "                                if float(actual_crack_width)>100 and float(actual_crack_width)<=125:\n",
    "                                    img_new_4[s:g,0:w,:][x,y]= COLORS[4]\n",
    "                                if float(actual_crack_width)>125 and float(actual_crack_width)<=150:\n",
    "                                    img_new_4[s:g,0:w,:][x,y]= COLORS[5]\n",
    "                                if float(actual_crack_width)>150 and float(actual_crack_width)<=175:\n",
    "                                    img_new_4[s:g,0:w,:][x,y]= COLORS[6]\n",
    "                                if float(actual_crack_width)>175 and float(actual_crack_width)<=200:\n",
    "                                    img_new_4[s:g,0:w,:][x,y]= COLORS[7]\n",
    "                                if float(actual_crack_width)>225 and float(actual_crack_width)<=250:\n",
    "                                    img_new_4[s:g,0:w,:][x,y]= COLORS[8]\n",
    "                                if float(actual_crack_width)>250 and float(actual_crack_width)<=500:\n",
    "                                    img_new_4[s:g,0:w,:][x,y]= COLORS[9]\n",
    "                                if float(actual_crack_width)>500 and float(actual_crack_width)<=1000:\n",
    "                                    img_new_4[s:g,0:w,:][x,y]= COLORS[10]        \n",
    "                                if float(actual_crack_width)>1000 and float(actual_crack_width)<=5000:\n",
    "                                    img_new_4[s:g,0:w,:][x,y]= COLORS[11]   \n",
    "                s = s + h_1 \n",
    "                g = g + h_1 \n",
    "                n += 1\n",
    "\n",
    "                cv2.imwrite(path_save + 'measure.png',img_new_4)\n",
    "            Avg_crack_width = mean(Crack_width_list)\n",
    "            crack_width_list.append(Avg_crack_width)\n",
    "    \n",
    "    #print(\"The number of crack is :\",k)   \n",
    "    #print(crack_width_list)\n",
    "    return img_new_4, crack_width_list\n",
    "            \n",
    "\n",
    "img_new_4,crack_width_list = crack_quantification(pred_mask,16,30000)\n",
    "Avg = mean(crack_width_list)\n",
    "print(\"The average crack width is:\", Avg)\n",
    "df = df1 = pd.DataFrame(crack_width_list)\n",
    "df.to_csv(\"D:\\Pengwei/crack_width_list.csv\")\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
